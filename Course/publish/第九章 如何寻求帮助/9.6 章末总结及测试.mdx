
## 章末总结及测试

你现在应该能够处理一系列 NLP 任务，并对它们进行微调或预训练模型。不要忘记在 [Model Hub](https://huggingface.co/models)(https://huggingface.co/models) 和社区分享你的结果。

我们迫不及待地想看到你利用所学知识创造出什么样的作品！

### 章末测试 

####  1. 应该按照什么顺序读取 Python 回溯？

1. 从上到下
2. 自下而上

####  2. 什么是最小可再生示例？

1. 来自一篇研究文章一个简单的 Transformer 体系结构的实现
2. 一种紧凑且自包含的代码块，可以在不依赖于私有文件或数据的情况下运行
3. Python traceback 的屏幕截图
4. 一个记录整个分析的 Notebook，包括与错误无关的部分

####  3. 假设你尝试运行以下代码，它抛出一个错误：

```python
from transformers import GPT3ForSequenceClassification

## ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
## ---------------------------------------------------------------------------
## ImportError                               Traceback (most recent call last)
## /var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_30848/333858878.py in <module>
## ----> 1 from transformers import GPT3ForSequenceClassification

## ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
```

以下哪项可能是有助于寻求帮助的论坛主题标题？
1. import错误:无法从'transformers'import 名称'GPT3GPT3ForSequenceClassification'(/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/_ init _. py) 
2. 从 transformers import gpt3forsequeclassification 时出现问题
3. 为什么我不能导入 GPT3ForSequenceClassification ?
4. Transformers 支持 GPT-3吗?

####  4. 假设你试图运行 `trainer.train ()`，但是遇到了一个错误，这个错误不能准确地告诉你错误来自哪里。下列哪一项是你应该首先在你的训练管道中寻找错误的地方？

1. 计算梯度并执行反向传播的优化步骤
2. 计算指标的评估步骤
3. 数据集
4. Dataloader

####  5. 调试 CUDA 错误的最好方法是什么？

1. 在论坛或 GitHub 上发布错误消息。
2. 在 CPU 上执行相同的代码。
3. 请阅读 traceback 以找出错误的原因。
4. 减少 batch size。
5. 重新启动 Jupyter 内核。

####  6. 修复 GitHub 上的问题最好的方法是什么？

1. 发布这个 bug 的完整可重复的例子。
2. 每天要求更新。
3. 检查错误周围的源代码，并试图找出错误发生的原因。在 issue 上发布结果。

####  7. 为什么对一个 batch 进行过拟合通常是一种好的调试技术？

1. 不是这样的， 过拟合总是不好的， 应该避免。
2. 这使我们能够验证该模型能够将损耗降低到零。
3. 过拟合可以检测我们验证我们输入和标签的张量形状是正确的。

####  8. 为什么在 Transformers 存储库中创建新问题时，使用 transformers-cli env 包含有关计算环境的详细信息是个好主意？

1. 它可以使维护人员理解你正在使用的库的哪个版本。
2. 它让维护人员知道你是在 Windows、 macOS 还是 Linux 上运行代码。
3. 它可以使维护人员知道你是在 GPU 还是 CPU 上运行代码。

### 解析

####  1. 应该按照什么顺序读取 Python 回溯？

正确选项: 2. 自下而上

1. 从上到下    
解析: 错误！大多数编程语言在顶部打印异常，但 Python 在这方面是特殊的。
2. 自下而上    
解析: 正确！Python 在底部显示异常回溯的一个优点是，方便在终端调试。

####  2. 什么是最小可再生示例？

正确选项: 2. 一种紧凑且自包含的代码块，可以在不依赖于私有文件或数据的情况下运行

1. 来自一篇研究文章一个简单的 Transformer 体系结构的实现    
解析: 虽然从头开始实现你自己的 Transformer 模型是非常有教育意义的，但这不是我们在这里讨论的内容。
2. 一种紧凑且自包含的代码块，可以在不依赖于私有文件或数据的情况下运行    
解析: 正确的！ 最少的可重现示例可以帮助库的维护人员重现你遇到的问题，以便他们可以更快地找到解决方案。
3. Python traceback 的屏幕截图    
解析: 再试一次 —— 尽管在提交问题时
4. 一个记录整个分析的 Notebook，包括与错误无关的部分    
解析: 不完全正确 —— 尽管共享一个显示错误的 Google Colab Notebook 会很有帮助

####  3. 假设你尝试运行以下代码，它抛出一个错误：

```python
from transformers import GPT3ForSequenceClassification

## ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
## ---------------------------------------------------------------------------
## ImportError                               Traceback (most recent call last)
## /var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_30848/333858878.py in <module>
## ----> 1 from transformers import GPT3ForSequenceClassification

## ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
```

以下哪项可能是有助于寻求帮助的论坛主题标题？
正确选项: 3. 为什么我不能导入 GPT3ForSequenceClassification ?

正确选项: 4. Transformers 支持 GPT-3吗?

1. import错误:无法从'transformers'import 名称'GPT3GPT3ForSequenceClassification'(/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/_ init _. py)     
解析: 包括 traceback 的最后一行可能会更具描述性，但最好保留在主体部分。再试一次！
2. 从 transformers import gpt3forsequeclassification 时出现问题    
解析: 再试一次——尽管这提供了有用的信息，但最好还是保留在文本的主体部分。
3. 为什么我不能导入 GPT3ForSequenceClassification ?    
解析: 不错的选择！这个标题是简洁的，并给读者一个线索，什么可能是错误的(即Transformers 不支持 GPT-3)。
4. Transformers 支持 GPT-3吗?    
解析: 好主意! 用问题作为主题标题是向社区传达问题的好方法。

####  4. 假设你试图运行 `trainer.train ()`，但是遇到了一个错误，这个错误不能准确地告诉你错误来自哪里。下列哪一项是你应该首先在你的训练管道中寻找错误的地方？

正确选项: 3. 数据集

1. 计算梯度并执行反向传播的优化步骤    
解析: 尽管优化器中可能存在缺陷， 但这通常是训练管道中的几个步骤， 因此首先要检查其他事项。再试一次!
2. 计算指标的评估步骤    
解析: 评估通常是在整个训练结束后进行的， 因此你应该首先检查训练管道的某个地方。
3. 数据集    
解析: 正确的!查看数据几乎总是你应该做的第一件事， 以确保文本进行了适当的编码， 具有预期的特性， 等等。
4. Dataloader    
解析: 再试一次—— 这非常接近你应该检查的第一件事。你还记得我们交给 dataloader 的是什么东西吗？

####  5. 调试 CUDA 错误的最好方法是什么？

1. 在论坛或 GitHub 上发布错误消息。    
解析: 这不会有什么帮助
2. 在 CPU 上执行相同的代码。    
解析: 没错
3. 请阅读 traceback 以找出错误的原因。    
解析: 对于任何其他错误
4. 减少 batch size。    
解析: 减少 batch size 通常是处理 CUDA 内存不足错误的一个好策略
5. 重新启动 Jupyter 内核。    
解析: 再试一次——重新启动内核不会让错误神奇地消失！

####  6. 修复 GitHub 上的问题最好的方法是什么？

正确选项: 1. 发布这个 bug 的完整可重复的例子。

1. 发布这个 bug 的完整可重复的例子。    
解析: 是的，这是帮助维护人员找到 bug 的最好方法。你还应该做什么？
2. 每天要求更新。    
解析: 这不太可能给你任何帮助；人们更可能会忽视你。
3. 检查错误周围的源代码，并试图找出错误发生的原因。在 issue 上发布结果。    
解析: 这肯定会对维护人员有帮助！如果你确实找到了 bug 的来源和修复程序

####  7. 为什么对一个 batch 进行过拟合通常是一种好的调试技术？

正确选项: 2. 这使我们能够验证该模型能够将损耗降低到零。

1. 不是这样的， 过拟合总是不好的， 应该避免。    
解析: 当对整个数据集进行训练时， 过拟合确实可能是一个不好的信号， 表明你的模型不能很好地推广到新的示例。但是， 对于调试， 我们通常不会对整个数据集进行训练。再试一次！
2. 这使我们能够验证该模型能够将损耗降低到零。    
解析: 正确! 只需要两个样本的很小的 batch，我们就可以快速验证模型是否具有学习能力。
3. 过拟合可以检测我们验证我们输入和标签的张量形状是正确的。    
解析: 再试一次 —— 如果你的张量形状不对齐， 那么你肯定不能训练， 即使是在一个 batch 里。

####  8. 为什么在 Transformers 存储库中创建新问题时，使用 transformers-cli env 包含有关计算环境的详细信息是个好主意？

正确选项: 1. 它可以使维护人员理解你正在使用的库的哪个版本。

正确选项: 2. 它让维护人员知道你是在 Windows、 macOS 还是 Linux 上运行代码。

正确选项: 3. 它可以使维护人员知道你是在 GPU 还是 CPU 上运行代码。

1. 它可以使维护人员理解你正在使用的库的哪个版本。    
解析: 正确! 由于库的每个主要版本在API中都可能有更改， 因此了解你正在使用的特定版本有助于缩小问题范围。其他好处是什么?
2. 它让维护人员知道你是在 Windows、 macOS 还是 Linux 上运行代码。    
解析: 正确！错误有时可能是由你正在使用的特定操作系统引起的， 了解这一点有助于维护人员在本地复现这些错误。但这并不是唯一的原因。
3. 它可以使维护人员知道你是在 GPU 还是 CPU 上运行代码。    
解析: 正确的！ 正如我们在本章中所见，在 GPU 或 CPU 上运行的代码可能会产生不同的结果或错误，了解你使用的是哪种硬件有助于吸引维护人员的注意力。 但这不是唯一的好处...

