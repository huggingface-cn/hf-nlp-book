# 第九章 构建与分享演示

在本章中，我们将学习如何为你的机器学习构建**交互式demo**模型。

为什么要为你的机器学习模型构建demo？

- **机器学习开发人员**可以轻松地向包括非技术团队或客户在内的广大受众展示他们的工作
- **研究人员**更轻松地重现机器学习模型和行为
- **质量测试人员**或**最终用户**更容易识别和调试模型的故障点
- **不同的用户**发现模型中的算法偏差

我们将使用 Gradio 库为我们的模型构建demo。Gradio 允许你完全使用 Python 为任何机器学习模型构建、自定义和共享基于 Web 的demo。

以下是一些使用 Gradio 构建的机器学习demo示例：

* 一个**草图识别**模型，它接收草图并输出它认为正在绘制的标签：

* 一个抽取式**问题回答**模型，它接受上下文段落和一个任务并输出一个结果和一个概率分数（我们在第7章中讨论了这种模型）：

* 一个**背景去除**模型，它接收图像并输出去除背景的图像：

本章分为两个部分，包括 `概念` 和 `应用程序` 。在你了解每个部分的概念后，你将应用它来构建特定类型的demo，范围从图像分类到语音识别。当你学习完本章后，就能够用几行 Python 代码构建这些demo。

👀 点击 <a href="https://huggingface.co/spaces" target="_blank">Hugging Face Spaces</a> 以查看机器学习社区构建的许多机器学习demo的最新示例！

## 9.1 使用Graadio构建演示 

让我们从安装 Gradio 开始吧！由于它是一个 Python 包，只需运行：
`$ pip install gradio` 

你可以在任何地方安装并运行 Gradio，无论是从你最喜欢的 Python IDE、Jupyter notebook 还是 Google Colab 🤯！

让我们从一个简单的“Hello World”示例开始，熟悉 Gradio 语法：

```python
import gradio as gr

def greet(name):
    return "Hello " + name

demo = gr.Interface(fn=greet, inputs="text", outputs="text")

demo.launch()
```

让我们学习一下上面的代码：

- 首先，我们定义一个名为 `greet()` 的函数。它是一个在你的名字前添加“Hello”的简单函数，但它通常可以是 `任何` Python 函数。例如，在机器学习应用程序中，此函数将 **调用模型以对输入进行预测** 并返回输出。
- 然后，我们创建一个带有三个参数的 Gradio `Interface` ，包括 `fn` 、 `inputs` 和 `outputs` 。这些参数定义了预测函数，我们想要的输入和输出组件的 `type` 。在本例中，两个组件都是简单的文本框。
- 最后，我们在我们创建的 `Interface` 上调用 `launch()` 方法。

如果你运行这段代码，下面的界面会自动出现在 Jupyter／Colab notebook 中，或者在浏览器中弹出 ** [http://localhost:7860](http://localhost:7860)(http://localhost:7860) ** 。

可以使用你自己的姓名或其他输入来使用此 GUI！在这个 GUI 中，Gradio 自动推断输入参数的名称 （ `name` ）并将其应用为文本框顶部的标签。如果你想改变它或者以其他方式自定义文本框该怎么办呢？在这种情况下，你可以实例化一个表示输入组件的类对象。

学习以下例子：

```python
import gradio as gr

def greet(name):
    return "Hello " + name

## 将文本框类实例化
textbox = gr.Textbox(label="Type your name here:", placeholder="John Doe", lines=2)

gr.Interface(fn=greet, inputs=textbox, outputs="text").launch()
```

在这里，我们创建了一个带有标签、占位符和一组行数的输入文本框。你可以对输出文本框执行相同的操作，但我们现在将其保留。

我们已经看到，只需几行代码，Gradio 就可以让你围绕任何具有任何类型输入或输出的函数创建一个简单的界面。在本节中，我们从一个简单的文本框开始，但在接下来的部分中，我们将介绍其他类型的输入和输出。现在让我们看看在 Gradio 应用程序中包含一些 NLP。

### 🤖 包括模型预测 

现在让我们构建一个简单的界面，让你可以演示像 GPT-2 这样的**文本生成**模型。

我们将使用 Transformers 中的 `pipeline()` 函数加载我们的模型。
如果你需要快速复习，你可以返回到第 1 章中的那个部分。

首先，我们定义一个接受文本提示并返回文本完成的预测函数：

```python
from transformers import pipeline

model = pipeline("text-generation")

def predict(prompt):
    completion = model(prompt)[0]["generated_text"]
    return completion
```

此函数完成你提供的提示，你可以使用自己的输入提示运行它以查看它是如何工作的。这是一个示例（你可能会得到不同的完成）：

```python
predict("My favorite programming language is")
```

```python
>> My favorite programming language is Haskell. I really enjoyed the Haskell language, but it doesn't have all the features that can be applied to any other language. For example, all it does is compile to a byte array.
```

现在我们有了一个生成预测的函数，我们可以像之前一样创建和启动一个“接口”：

```python
import gradio as gr

gr.Interface(fn=predict, inputs="text", outputs="text").launch()
```

就是这样！你现在可以使用此接口使用 GPT-2 模型生成文本，如下所示 🤯:

继续阅读以了解如何使用 Gradio 构建其他类型的演示！

## 9.2 了解 `Interface`接口类

在本节中，我们将仔细研究 `Interface` 类，并了解用于创建其的主要参数。

### 如何创建接口

你会注意到 `Interface` 类有 3 个必需参数：
`Interface(fn, inputs, outputs, ...)`

这些参数是：

- `fn` ：由 Gradio 接口包装的预测函数。该函数可以接受一个或多个参数并返回一个或多个值
- `inputs` ：输入组件类型。Gradio 提供了许多预构建的组件，例如 `"image"` 或 `"mic"` 。
- `outputs` ：输出组件类型。同样，Gradio 提供了许多预构建的组件，例如 `“图像”` 或“标签” `。

有关组件的完整列表， 每个预构建的组件都可以通过实例化该组件对应的类来定制。

例如，正如我们看到的，你可以传入一个 `Textbox（lines=7, label="Prompt")`组件来创建一个包含 7 行和一个标签的文本框，而不是将 `"textbox"`传递给 `inputs`参数。
让我们看另一个例子，这次是一个 `Audio`组件。

### 一个带音频的简单示例

如前所述，Gradio 提供了许多不同的输入和输出。
因此，让我们构建一个适用于音频的“接口”。

在这个例子中，我们将构建一个音频到音频的函数，它需要一个音频文件并简单地反转它。

我们将使用 `Audio`组件作为输入。 使用 `Audio`组件时，你可以指定希望音频的 `source`是用户上传的文件还是用户录制声音的麦克风。 在这种情况下，让我们将其设置为“麦克风”。 只是为了好玩，我们会在我们的“音频”中添加一个标签，上面写着“在这里说话……”。

此外，我们希望将音频作为 numpy 数组接收，以便我们可以轻松地“反转”它。 所以我们将 `"type"`设置为 `"numpy"`，它会传递输入data 作为 (`sample_rate`,`data`) 的元组进入我们的函数。

我们还将使用 `Audio`输出组件，它可以自动将具有采样率和 numpy 数据数组的元组渲染为可播放的音频文件。 在这种情况下，我们不需要进行任何自定义，因此我们将使用字符串快捷方式“audio”。
上面的代码会产生一个类似下面的界面（如果你的浏览器没有询问你的麦克风权限， `<a href="https://huggingface.co/spaces/course-demos/audio-reverse" target="_blank">`open the demo in  a separate tab `</a>`.)

你现在应该能够录制自己的声音并听到自己在反向说话 -  👻!

### `launch()`方法

到目前为止，我们已经使用了 `launch()`方法来启动界面，但是我们
还没有真正讨论过它的作用。

默认情况下，`launch()`方法将在 Web 服务器中启动demo正在本地运行。 如果你在 Jupyter 或 Colab 笔记本中运行代码，那么Gradio 会将demo GUI 嵌入到笔记本中，以便你轻松使用它。

你可以通过不同的参数自定义 `launch()`的行为：

  -`inline`- whether to display the interface inline on Python notebooks.
  -`inbrowser`- whether to automatically launch the interface in a new tab on the default browser.
  -`share`- whether to create a publicly shareable link from your computer for the interface. Kind of like a Google Drive link!

我们将在下一节中更详细地介绍 `share`参数！

### ✏️ 让我们应用它！

让我们构建一个界面，让你demo **speech-recognition** 模型。
为了让它变得有趣，我们将接受 `or`麦克风输入或上传的文件。

像往常一样，我们将使用 Transformers 中的 `pipeline()`函数加载我们的语音识别模型。如果你需要快速复习，你可以返回＋－｜－－11－－｜－＋。 接下来，我们将实现一个 `transcribe_audio()`函数来处理音频并返回转录。 最后，我们将把这个函数包装在一个 `Interface`中，其中 `Audio`组件用于输入，只有文本用于输出。 总而言之，此应用程序的代码如下：
＋－｜－－2－－｜－＋
如果你的浏览器没有要求你提供麦克风权限，`<a href="https://huggingface.co/spaces/course-demos/audio-reverse" target="_blank">`open the demo in a separate tab`</a>`.

就是这样！ 你现在可以使用此界面来转录音频。 注意这里
通过将 `optional`参数作为 ` True` 传递，我们允许用户
提供麦克风或音频文件（或两者都不提供，但这会返回错误消息）。

继续看看如何与他人分享你的界面！

## 如何与他人分享demo？

现在你已经构建了一个demo，你可能希望与其他人分享它。梯度demo可以通过两种方式共享：使用 ***temporary share link*** 或 ***permanent hosting on Spaces***。

我们将很快介绍这两种方法。但在分享demo之前，你可能需要完善它 💅。

### 打磨你的 Gradio demo：

![Overview of a gradio interface](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter9/gradio-demo-overview.png "Overview of a gradio interface")

为了给你的demo添加额外的内容， `Interface` 类支持一些可选参数：
    - `title` ：你可以给你的demo一个标题，它出现在输入和输出组件的上方。
    - `description` ：你可以为界面提供描述（文本、Markdown 或 HTML），显示在输入和输出组件的上方和标题下方。
    - `article` ：你还可以编写扩展文章（文本、Markdown 或 HTML）来解释界面。如果提供，它会出现在输入和输出组件的_下方。
    - `theme` ：不喜欢默认颜色？将主题设置为使用 `default` 、 `huggingface` 、 `grass` 、 `peach` 之一。你还可以添加 `dark-` 前缀，例如 `dark-peach` 用于深色主题（或者只是 `dark` 用于默认的深色主题）。
    - `examples` ：为了让你的demo `更易于使用` ，你可以为函数提供一些示例输入。它们出现在 UI 组件下方，可用于填充界面。这些应该作为嵌套列表提供，其中外部列表由样本组成，每个内部列表对应于每个输入组件的输入组成。
    - `live` ：如果你想让你的demo“活”，这意味着你的模型每次输入更改时都会重新运行，你可以设置 `live=True` 。这对使用快速模型很有意义（我们将在本节末尾看到一个示例）
使用上面的选项，我们最终得到了一个更完整的界面。运行下面的代码，以便与 Rick and Morty 聊天：

```python
title = "Ask Rick a Question"
description = """
The bot was trained to answer questions based on Rick and Morty dialogues. Ask Rick anything!
<img src="https://huggingface.co/spaces/course-demos/Rick_and_Morty_QA/resolve/main/rick.png" width=200px>
"""

article = "Check out [the original Rick and Morty Bot](https://huggingface.co/spaces/kingabzpro/Rick_and_Morty_Bot)(https://huggingface.co/spaces/kingabzpro/Rick_and_Morty_Bot) that this demo is based off of."

gr.Interface(
    fn=predict,
    inputs="textbox",
    outputs="text",
    title=title,
    description=description,
    article=article,
    examples=[["What are you doing?"], ["Where should we time travel to?"]],
).launch()
```

使用上面的选项，我们最终得到了一个更完整的界面。试试下面的界面：

### 使用临时链接分享你的demo

现在我们已经有了机器学习模型的工作demo，让我们学习如何轻松共享指向我们界面的链接。
通过在 `launch()` 方法中设置 `share=True` 可以轻松地公开共享接口：

```python
gr.Interface(classify_image, "image", "label").launch(share=True)
```

这会生成一个公开的、可共享的链接，你可以将其发送给任何人！当你发送此链接时，另一方的用户可以在浏览器中试用该模型长达 72 小时。因为处理发生在你的设备上（只要你的设备保持开启！），你不必担心打包任何依赖项。如果你使用 Google Colab 笔记本工作，则始终会自动创建共享链接。它通常看起来像这样：**XXXXX.gradio.app**。虽然链接是通过 Gradio 链接提供的，但我们只是你本地服务器的代理，不会存储通过接口发送的任何数据。

但是请记住，这些链接是可公开访问的，这意味着任何人都可以使用你的模型进行预测！因此，请确保不要通过你编写的函数公开任何敏感信息，或允许在你的设备上发生任何关键更改。如果设置 `share=False` （默认值），则仅创建本地链接。

### 在 Hugging Face Spaces 上托管你的demo

可以传递给同事的共享链接很酷，但是如何永久托管你的demo并让它存在于互联网上自己的“空间”中？

Hugging Face Spaces 提供了在互联网上永久托管 Gradio 模型的基础设施，**免费**！Spaces 允许你创建并推送到（公共或私人）存储库，
你的 Gradio 在哪里
接口代码将存在于 `app.py` 文件中。 [阅读分步教程](https://huggingface.co/blog/gradio-spaces)(https://huggingface.co/blog/gradio-spaces) 开始使用，或观看下面的示例视频。

### ✏️ 让我们应用它！

使用到目前为止我们在各节中学到的知识，让我们创建我们在本章第一节中看到的草图识别demo。让我们为我们的界面添加一些自定义并设置 `share=True` 以创建一个我们可以传递的公共链接。

我们可以从 [class_names.txt](https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/class_names.txt)(https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/class_names.txt) 加载标签，并从 [pytorch_model.bin](https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/pytorch_model.bin)(https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/pytorch_model.bin) 加载预训练的 pytorch 模型 通过点击链接并单击文件预览左上角的下载来下载这些文件。让我们看看下面的代码，看看我们如何使用这些文件来加载我们的模型并创建一个 `predict()` 函数：

```python
from pathlib import Path
import torch
import gradio as gr
from torch import nn

LABELS = Path("class_names.txt").read_text().splitlines()

model = nn.Sequential(
    nn.Conv2d(1, 32, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(32, 64, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(64, 128, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Flatten(),
    nn.Linear(1152, 256),
    nn.ReLU(),
    nn.Linear(256, len(LABELS)),
)
state_dict = torch.load("pytorch_model.bin", map_location="cpu")
model.load_state_dict(state_dict, strict=False)
model.eval()

def predict(im):
    x = torch.tensor(im, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0
    with torch.no_grad():
        out = model(x)
    probabilities = torch.nn.functional.softmax(out[0], dim=0)
    values, indices = torch.topk(probabilities, 5)
    return {LABELS[i]: v.item() for i, v in zip(indices, values)}
```

现在我们有了一个 `predict()` 函数。下一步是定义并启动我们的渐变界面：

```python
interface = gr.Interface(
    predict,
    inputs="sketchpad",
    outputs="label",
    theme="huggingface",
    title="Sketch Recognition",
    description="Who wants to play Pictionary? Draw a common object like a shovel or a laptop, and the algorithm will guess in real time!",
    article="<p style='text-align: center'>Sketch Recognition | Demo Model</p>",
    live=True,
)
interface.launch(share=True)
```

注意 `Interface` 中的 `live=True` 参数，这意味着草图demo使
每次有人在画板上画画时的预测（没有提交按钮！）。

此外，我们还在 `launch()` 方法中设置了 `share=True` 参数。
这将创建一个公共链接，你可以发送给任何人！当你发送此链接时，对方的用户可以尝试草图识别模型。重申一下，你还可以在 Hugging Face Spaces 上托管模型，这就是我们能够嵌入上面的demo的方式。

接下来，我们将介绍 Gradio 可用于 Hugging Face 生态系统的其他方式！

# 从 Hugging Face Spaces 空间加载 
要从 hugs Face Hub 加载任何空间并在本地重新创建它，你可以将 `spaces/` 传递给 `Interface` ，再加上空间的名称。

还记得第 1 节中删除图像背景的demo吗？让我们从 Hugging Face Spaces 加载它：

```python
gr.Interface.load("spaces/abidlabs/remove-bg").launch()
```

从Hub 或 Spaces 加载demo的一个很酷的地方是，你可以通过覆盖任何参数来自定义它们。在这里，我们添加一个标题并让它与网络摄像头一起使用：

```python
gr.Interface.load(
    "spaces/abidlabs/remove-bg", inputs="webcam", title="Remove your webcam background!"
).launch()
```

现在我们已经探索了几种将 Gradio 与 hugs Face Hub 集成的方法，让我们来看看 `Interface` 类的一些高级功能。这就是下一节的主题！

## 9.4 高级Interface功能及Blocks介绍

现在我们可以构建和共享一个基本接口，让我们来探索一些更高级的特性，如状态和解释，同时了解`gradio.Blocks` 低级 API。

### 使用状态保存数据 

Gradio 支持 `会话状态` ，其中数据在页面加载中的多个提交中持续存在。会话状态对于构建demo很有用，例如，你希望在用户与模型交互时保留数据的聊天机器人。请注意，会话状态不会在模型的不同用户之间共享数据。

要将数据存储在会话状态中，你需要做三件事：

1。向函数中传递一个 `额外的参数` , 该参数表示接口的状态。
1. 在函数结束时，将状态的更新值作为 `额外的返回值` 返回。
1. 在创建 `接口` 时添加 'state' 输入和 'state' 输出组件。

请参阅下面的聊天机器人示例：

```python
import random

import gradio as gr

def chat(message, history):
    history = history or []
    if message.startswith("How many"):
        response = random.randint(1, 10)
    elif message.startswith("How"):
        response = random.choice(["Great", "Good", "Okay", "Bad"])
    elif message.startswith("Where"):
        response = random.choice(["Here", "There", "Somewhere"])
    else:
        response = "I don't know"
    history.append((message, response))
    return history, history

iface = gr.Interface(
    chat,
    ["text", "state"],
    ["chatbot", "state"],
    allow_screenshot=False,
    allow_flagging="never",
)
iface.launch()
```

请注意输出组件的状态如何在提交之间保持不变。注意：可以给 state 参数传入一个默认值，作为 state 的初始值。

#### 通过解释来理解预测 

大多数机器学习模型都是黑盒子，函数的内部逻辑对终端用户是隐藏的。为了提高透明度，我们通过简单地将 Interface 类中的解释关键字设置为默认值，使向模型添加解释变得非常容易。这允许你的用户理解输入的哪些部分负责输出。看看下面这个简单的接口，它显示了一个还包括解释的图像分类器：

```python
import requests
import tensorflow as tf

import gradio as gr

inception_net = tf.keras.applications.MobileNetV2()  # load the model

## 下载 ImageNet 的可读标签
response = requests.get("https://git.io/JJkYN")
labels = response.text.split("\n")

def classify_image(inp):
    inp = inp.reshape((-1, 224, 224, 3))
    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)
    prediction = inception_net.predict(inp).flatten()
    return {labels[i]: float(prediction[i]) for i in range(1000)}

image = gr.Image(shape=(224, 224))
label = gr.Label(num_top_classes=3)

title = "Gradio Image Classifiction + Interpretation Example"
gr.Interface(
    fn=classify_image, inputs=image, outputs=label, interpretation="default", title=title
).launch()
```

通过提交一个输入，然后单击输出组件下的 Interpret 来测试解释功能。

除了 Gradio 提供的默认解释方法之外，你还可以为 `interpretation` 参数指定 `shap` ，并设置 `num_shap` 参数。这使用基于 Shapley 的解释，你可以在 [here](https://christophm.github.io/interpretable-ml-book/shap.html)(https://christophm.github.io/interpretable-ml-book/shap.html) 阅读更多信息。最后，还可以将自己的解释函数传入 `interpretation` 参数。在 Gradio 的入门页面 [here](https://gradio.app/getting_started/)(https://gradio.app/getting_started/) 中可以看到一个例子。

这结束了我们对 Gradio 的 `Interface` 类的深入研究。正如我们所看到的，这个类使用几行 Python 代码创建机器学习demo变得简单。然而，有时你会想通过改变布局或链接多个预测函数来定制你的 demo。如果我们能以某种方式将 `接口` 分成可定制的 "块"，那不是很好吗？幸运的是，有！这是最后一部分的主题。

### Blocks块

在前面的部分中，我们已经使用 `Interface` 类探索并创建了demo。在本节中，我们将介绍我们 **新开发**的称为 `gradio.Blocks` 低级 API。

现在， `接口` 和 `块` 之间有什么区别？

- ⚡ `接口` ：一个高级 API，让你只需提供输入和输出列表即可创建完整的机器学习demo。

- 🧱 `块` ：一个低级的 API，它允许你完全控制你的应用程序的数据流和布局。你可以使用 `块` （如 "构建块"）构建非常复杂的多步骤应用程序。

#### 为什么要块 🧱？

正如我们在前几节中看到的， `Interface` 类允许你使用几行代码轻松创建成熟的机器学习 demo。 `Interface` API 非常易于使用，但缺乏 `Blocks` API 提供的灵活性。例如，你可能想要：

- 将相关demo组合为一个 web 应用程序中的多个选项卡
- 更改 demo 的布局，例如指定输入和输出的位置
- 具有多步骤接口，其中一个模型的输出成为下一个模型的输入，或者通常具有更灵活的数据流
- 根据用户输入更改组件的属性 （例如，下拉列表中的选项） 或其可见性

我们将在下面探讨所有这些概念。

#### 使用块创建简单 demo 

安装 Gradio 后，将以下代码作为 Python 脚本、Jupyter 笔记本或 Colab 笔记本运行。

```python
import gradio as gr

def flip_text(x):
    return x[::-1]

demo = gr.Blocks()

with demo:
    gr.Markdown(
        """
    # Flip Text!
    Start typing below to see the output.
    """
    )
    input = gr.Textbox(placeholder="Flip this text")
    output = gr.Textbox()

    input.change(fn=flip_text, inputs=input, outputs=output)

demo.launch()
```

上述简单示例介绍了块的 4 个基本概念：

1. 块允许你允许你构建结合 markdown、HTML、按钮和交互组件的 web 应用程序，只需在一个带有 gradio 的 Python 中实例化对象。
<div custom-style="Tip-green">

🙋如果你不熟悉 Python 中的 `with` 语句，我们建议你查看来自 Real Python 的极好的 [教程](https://realpython.com/python-with-statement)(https://realpython.com/python-with-statement) 。看完后回到这里 
</div>
实例化组件的顺序很重要，因为每个元素都按照创建的顺序呈现到 Web 应用程序中。（更复杂的布局在下面讨论）

2. 你可以在代码中的任何位置定义常规 Python 函数，并使用 `块` 在用户输入的情况下运行它们。在我们的示例中，们有一个"翻转"输入文本的简单函数，但你可以编写任何 Python 函数，从简单的计算到处理机器学习模型的预测。

3. 你可以将事件指定给任何 `块` 组件。这将在组件被单击、更改等情况下运行函数。当你分配一个事件时，你传入三个参数： `fn` ：应该被调用的函数， `inputs` ：输入组件的（列表），以及 `outputs` ：应该被调用的输出组件的（列表）。

   在上面的示例中，当名为 `input` 的 `Textbox` 中的值发生变化时，我们运行 `flip_text()` 函数。该事件读取 `输入` 中的值，将其作为名称参数传递给 `flip_text()` ，然后它返回一个值，该值被分配给我们的第二个名为 `output` 的 `Textbox` 。

   要查看每个组件支持的事件列表，请参阅 Gradio [文档](https://www.gradio.app/docs)(https://www.gradio.app/docs) 。

4. 块会根据你定义的事件触发器自动确定组件是否应该是交互式的 （接受用户输入）。在我们的示例中，第一个文本框是交互式的，因为它的值由 `flip_text()` 函数使用。第二个文本框不是交互式的，因为它的值从不用作输入。在某些情况下，你可能想要覆盖它，你可以通过传递一个布尔值给组件的 `交互` 参数（例如 `gr.Textbox(placeholder="Flip this text", interactive=True)` ）。

#### 自定义demo的布局 

我们如何使用 `块` 来定制我们的demo的布局？默认情况下， `块` 在一列中垂直呈现创建的组件。你可以通过使用 `with gradio.Column():` 创建其他列或使用 `with gradio.Row():` 创建其他行并在这些上下文中创建组件来改变这一点。

你应该记住：在 `列` 下创建的任何组件（这也是默认设置） 都将垂直布局。在 `Row` 下创建的任何组件都将水平布局，类似于 [Web 开发中的 flexbox 模型](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox)(https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox) 。

最后，你还可以使用 `with gradio.Tabs()` 上下文管理器为你的 demo 创建选项卡。在此上下文中，你可以通过使用 `gradio.TabItem(name_of_tab):` 指定来创建多个选项卡。在 `gradio.TabItem(name_of_tab):` 中创建的任何组件都会出现在该选项卡中。

现在让我们在 demo 中添加一个 `flip_image()` 函数并添加一个翻转图像的新选项卡。下面是一个带有 2 个选项卡的示例，也使用了一个行：

```python
import numpy as np
import gradio as gr

demo = gr.Blocks()

def flip_text(x):
    return x[::-1]

def flip_image(x):
    return np.fliplr(x)

with demo:
    gr.Markdown("Flip text or image files using this demo.")
    with gr.Tabs():
        with gr.TabItem("Flip Text"):
            with gr.Row():
                text_input = gr.Textbox()
                text_output = gr.Textbox()
            text_button = gr.Button("Flip")
        with gr.TabItem("Flip Image"):
            with gr.Row():
                image_input = gr.Image()
                image_output = gr.Image()
            image_button = gr.Button("Flip")

    text_button.click(flip_text, inputs=text_input, outputs=text_output)
    image_button.click(flip_image, inputs=image_input, outputs=image_output)

demo.launch()
```


你会注意到，在这个示例中，我们还在每个选项卡中创建了一个 `Button` 组件，并且我们为每个按钮分配了一个点击事件，这是实际运行该函数的事件。

#### 探索事件和状态 

正如你可以控制布局一样， `块` 可以让你对触发函数调用的事件进行细粒度控制。每个组件和许多布局都有它们支持的特定事件。

例如， `Textbox` 组件有两个事件： `change()` （当文本框内的值发生变化时），和 `submit()` （当用户在关注文本框时按下 enter 键）。更复杂的组件可以有更多的事件：例如， `Audio` 组件也有单独的事件，用于播放、清除、暂停音频文件等。请参阅文档了解每个组件支持的事件。

你可以将事件触发器附加到这些事件中的一个、一个或多个。你可以通过在组件实例中调用事件名称作为函数来创建一个事件触发器 -- 例如 `textbox.change(...)` 或 `btn.click(...)` 。如前所述，该函数接受三个参数：

- `fn` ：要运行的函数
- `inputs` ：组件的（列表），其值应作为函数的输入参数提供。每个组件的值按顺序映射到相应的函数参数。如果函数不带任何参数，则此参数可以为 None。
- `outputs` ：应根据函数返回的值更新其值的组件（列表）。每个返回值按顺序设置相应组件的值。如果函数不返回任何内容，则此参数可以为 None。

你甚至可以使输入和输出组件成为同一个组件，就像我们在这个使用 GPT 模型进行文本补全的示例中所做的那样：

```python
import gradio as gr

api = gr.Interface.load("huggingface/EleutherAI/gpt-j-6B")

def complete_with_gpt(text):
    # Use the last 50 characters of the text as context
    return text[:-50] + api(text[-50:])

with gr.Blocks() as demo:
    textbox = gr.Textbox(placeholder="Type here and press enter...", lines=4)
    btn = gr.Button("Generate")

    btn.click(complete_with_gpt, textbox, textbox)

demo.launch()
```

#### 创建多步 demo 

在某些情况下，你可能需要一个 ＿多步骤的 demo＿, 其中重用一个函数的输出作为下一个函数的输入。使用 `块` 很容易做到这一点，因为你可以使用组件作为一个事件触发器的输入，但作为另一个事件触发器的输出。看看下面示例中的文本组件，它的值是语音到文本模型的结果，但也被传递到情感分析模型：

```python
from transformers import pipeline

import gradio as gr

asr = pipeline("automatic-speech-recognition", "facebook/wav2vec2-base-960h")
classifier = pipeline("text-classification")

def speech_to_text(speech):
    text = asr(speech)["text"]
    return text

def text_to_sentiment(text):
    return classifier(text)[0]["label"]

demo = gr.Blocks()

with demo:
    audio_file = gr.Audio(type="filepath")
    text = gr.Textbox()
    label = gr.Label()

    b1 = gr.Button("Recognize Speech")
    b2 = gr.Button("Classify Sentiment")

    b1.click(speech_to_text, inputs=audio_file, outputs=text)
    b2.click(text_to_sentiment, inputs=text, outputs=label)

demo.launch()
```

#### 更新组件属性 

到目前为止，我们已经了解了如何创建事件来更新另一个组件的值。但是，如果你想更改组件的其他属性，例如文本框的可见性或单选按钮组中的选项，会发生什么？你可以通过返回组件类的 `update()` 方法而不是函数的常规返回值来做到这一点。

这很容易用一个例子来说明：

```python
import gradio as gr

def change_textbox(choice):
    if choice == "short":
        return gr.Textbox.update(lines=2, visible=True)
    elif choice == "long":
        return gr.Textbox.update(lines=8, visible=True)
    else:
        return gr.Textbox.update(visible=False)

with gr.Blocks() as block:
    radio = gr.Radio(
        ["short", "long", "none"], label="What kind of essay would you like to write?"
    )
    text = gr.Textbox(lines=2, interactive=True)

    radio.change(fn=change_textbox, inputs=radio, outputs=text)
    block.launch()
```

我们刚刚探索了 `块` 的所有核心概念！就像 `参数一样` ，你可以创建很酷的 demo，可以通过在 `launch()` 方法中使用 `share=True` 来共享，或者部署在 [Hugging Face Spaces](https://huggingface.co/spaces)(https://huggingface.co/spaces) 上。