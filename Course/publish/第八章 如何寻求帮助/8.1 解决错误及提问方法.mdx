## 8.1 è§£å†³é”™è¯¯åŠæé—®æ–¹æ³•

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç ”ç©¶å½“ä½ å°è¯•ä»æ–°è°ƒæ•´çš„ Transformer æ¨¡å‹ç”Ÿæˆé¢„æµ‹æ—¶å¯èƒ½å‘ç”Ÿçš„ä¸€äº›å¸¸è§é”™è¯¯ã€‚æœ¬èŠ‚ä¸ºç¬¬å››èŠ‚åšå‡†å¤‡ï¼Œæ¢ç´¢å¦‚ä½•è°ƒè¯•è®­ç»ƒé˜¶æ®µæœ¬èº«ã€‚

æˆ‘ä»¬ä¸ºè¿™ä¸€èŠ‚å‡†å¤‡äº†ä¸€ä¸ª [æ¨¡æ¿æ¨¡å‹åº“](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28)(https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28) ï¼Œå¦‚æœä½ æƒ³è¿è¡Œæœ¬ç« ä¸­çš„ä»£ç ï¼Œé¦–å…ˆéœ€è¦å°†æ¨¡å‹å¤åˆ¶åˆ°è‡ªå·±çš„ [Hugging Face Hub](https://huggingface.co)(https://huggingface.co) è´¦å·ã€‚è¿™éœ€è¦ä½ åœ¨ Jupyter Notebook ä¸­è¿è¡Œä»¥ä¸‹ä»»ä¸€å‘½ä»¤æ¥ç™»å½•ï¼š

```python
from huggingface_hub import notebook_login

notebook_login()
```

æˆ–åœ¨ä½ æœ€å–œæ¬¢çš„ç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```python
huggingface-cli login
```

è¿™é‡Œå°†ä¼šæç¤ºä½ è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ï¼Œå¹¶ä¿å­˜ä¸€ä¸ªä»¤ç‰Œ `~/.cache/huggingface/` ã€‚å®Œæˆç™»å½•åï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½å¤åˆ¶æ¨¡æ¿å­˜å‚¨åº“ï¼š

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name

def copy_repository_template():
    # å…‹éš†å­˜å‚¨åº“å¹¶æå–æœ¬åœ°è·¯å¾„
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # åœ¨Hubä¸Šåˆ›å»ºä¸€ä¸ªæ–°ä»“åº“
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # å…‹éš†ç©ºä»“åº“
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # å¤åˆ¶æ–‡ä»¶
    copy_tree(template_repo_dir, new_repo_dir)
    # ä¸Šä¼ åˆ°Hubä¸Š
    repo.push_to_hub()
```

ç°åœ¨å½“ä½ è°ƒç”¨ `copy_repository_template()` æ—¶ï¼Œå®ƒå°†åœ¨ä½ çš„å¸æˆ·ä¸‹åˆ›å»ºæ¨¡æ¿å­˜å‚¨åº“çš„å‰¯æœ¬ã€‚

### ä» Transformers è°ƒè¯• `pipeline` 

æ¥ä¸‹æ¥è¦å¼€å§‹æˆ‘ä»¬è°ƒè¯• Transformer æ¨¡å‹çš„å¥‡å¦™ä¸–ç•Œä¹‹æ—…ï¼Œè¯·è€ƒè™‘ä»¥ä¸‹æƒ…æ™¯ï¼šä½ æ­£åœ¨ä¸ä¸€ä½åŒäº‹åˆä½œè¿›è¡Œä¸€ä¸ªæé—®-å›ç­”çš„é¡¹ç›®ï¼Œè¿™ä¸ªé¡¹ç›®ç”¨æ¥å¸®åŠ©ç”µå­å•†åŠ¡ç½‘ç«™çš„å®¢æˆ·æ‰¾åˆ°æœ‰å…³æ¶ˆè´¹å“çš„ç­”æ¡ˆã€‚ä½ çš„åŒäº‹ç»™ä½ å‘äº†ä¸€æ¡æ¶ˆæ¯ï¼Œä¸¾ä¸ªä¾‹å­ï¼š

> å—¨ï¼æˆ‘åˆšåˆšä½¿ç”¨äº† Hugging Face è¯¾ç¨‹çš„ç¬¬ä¸ƒç« ä¸­çš„æŠ€æœ¯è¿›è¡Œäº†ä¸€ä¸ªå®éªŒï¼Œå¹¶åœ¨ SQuAD ä¸Šè·å¾—äº†ä¸€äº›å¾ˆæ£’çš„ç»“æœï¼æˆ‘è§‰å¾—æˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¨¡å‹ä½œä¸ºé¡¹ç›®çš„èµ·ç‚¹ã€‚Hub ä¸Šçš„æ¨¡å‹ ID æ˜¯ "lewtun/distillbert-base-uncased-finetuned-squad-d5716d28"ã€‚ä½ æ¥æµ‹è¯•ä¸€ä¸‹ ï¼‰

ä½ é¦–å…ˆæƒ³åˆ°çš„æ˜¯ä½¿ç”¨ Transformers ä¸­çš„ `pipeline` ï¼š

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å•Šå“¦ï¼Œå¥½åƒå‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼å¦‚æœä½ æ˜¯ç¼–ç¨‹æ–°æ‰‹ï¼Œè¿™ç±»é”™è¯¯ä¸€å¼€å§‹çœ‹èµ·æ¥æœ‰ç‚¹ç¥ç§˜ ï¼ˆç”šè‡³æ˜¯ä¸€ä¸ª `OSError` ï¼Ÿï¼‰ã€‚å…¶å®è¿™é‡Œæ˜¾ç¤ºçš„é”™è¯¯åªæ˜¯ä¸€ä¸ªæ›´å¤§çš„é”™è¯¯æŠ¥å‘Šä¸­æœ€åä¸€éƒ¨åˆ†ï¼Œç§°ä¸º `Python traceback` ï¼ˆåˆåå †æ ˆè·Ÿè¸ªï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨ Google Colab ä¸Šè¿è¡Œæ­¤ä»£ç ï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼äºä»¥ä¸‹å±å¹•æˆªå›¾çš„å†…å®¹ï¼š

![A Python traceback.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png "A Python traceback.")

è¿™äº›æŠ¥å‘Šä¸­åŒ…å«å¾ˆå¤šä¿¡æ¯ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¥çœ‹çœ‹å…³é”®éƒ¨åˆ†ã€‚è¯»å–æŠ¥å‘Šæ—¶çš„é¡ºåºæ¯”è¾ƒç‰¹æ®Šï¼Œåº”è¯¥ä» `ä»åº•éƒ¨åˆ°é¡¶éƒ¨` è¯»å–å›æº¯ï¼Œå¦‚æœä½ ä¹ æƒ¯äºä»ä¸Šåˆ°ä¸‹é˜…è¯»è‹±æ–‡æ–‡æœ¬ï¼Œè¿™å¯èƒ½å¬èµ·æ¥å¾ˆå¥‡æ€ªï¼Œä½†å®ƒåæ˜ äº†ä¸€ä¸ªäº‹å®ï¼šå›æº¯æ˜¾ç¤ºäº†åœ¨ä¸‹è½½æ¨¡å‹å’Œæ ‡è®°å™¨æ—¶ `pipeline` è°ƒç”¨çš„å‡½æ•°åºåˆ—ã€‚ï¼ˆæŸ¥çœ‹ç¬¬äºŒç« äº†è§£æœ‰å…³ `pipeline` å¦‚ä½•åœ¨åå°å·¥ä½œçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚ï¼‰

<div custom-style="Tip-red">

ğŸš¨ çœ‹åˆ° Google Colab å›æº¯ä¸­ "6 å¸§" å‘¨å›´çš„è“è‰²æ¡†äº†å—ï¼Ÿè¿™æ˜¯ Colab çš„ä¸€ä¸ªç‰¹æ®ŠåŠŸèƒ½ï¼Œå®ƒå°†å›æº¯å‹ç¼©ä¸º"å¸§"ã€‚å¦‚æœä½ æ— æ³•æ‰¾åˆ°é”™è¯¯çš„æ¥æºï¼Œå¯ä»¥é€šè¿‡å•å‡»è¿™ä¸¤ä¸ªå°ç®­å¤´æ¥å±•å¼€å®Œæ•´çš„å›æº¯ã€‚

</div>

è¿™æ„å‘³ç€å›æº¯çš„æœ€åä¸€è¡ŒæŒ‡ç¤ºæœ€åä¸€æ¡é”™è¯¯æ¶ˆæ¯å¹¶ç»™å‡ºå¼•å‘çš„å¼‚å¸¸åç§°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¼‚å¸¸ç±»å‹æ˜¯ `OSError` ï¼Œè¡¨ç¤ºä¸ç³»ç»Ÿç›¸å…³çš„é”™è¯¯ã€‚å¦‚æœæˆ‘ä»¬é˜…è¯»éšä¹‹é™„ç€çš„é”™è¯¯æ¶ˆæ¯ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„ `config.json` æ–‡ä»¶ä¼¼ä¹æœ‰é—®é¢˜ï¼Œè¿™é‡Œç»™å‡ºä¸¤ä¸ªä¿®å¤çš„å»ºè®®ï¼š

```python
"""
ç¡®ä¿:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<div custom-style="Tip-green">

ğŸ’¡ å¦‚æœä½ é‡åˆ°éš¾ä»¥ç†è§£çš„é”™è¯¯æ¶ˆæ¯ï¼Œåªéœ€å°†è¯¥æ¶ˆæ¯å¤åˆ¶å¹¶ç²˜è´´åˆ° Google æˆ– [Stack Overflow](https://stackoverflow.com)(https://stackoverflow.com) æœç´¢æ ä¸­ã€‚ä½ å¾ˆæœ‰å¯èƒ½ä¸æ˜¯ç¬¬ä¸€ä¸ªé‡åˆ°é”™è¯¯çš„äººï¼Œè¿™å¯ä»¥åœ¨ç¤¾åŒºä¸­æ‰¾åˆ°å…¶ä»–äººå‘å¸ƒçš„è§£å†³æ–¹æ¡ˆã€‚ä¾‹å¦‚ï¼Œåœ¨ Stack Overflow ä¸Šæœç´¢ `OSError: Can't load config for` ç»™å‡ºäº†å‡ ä¸ª [hits](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+)(https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+) ï¼Œè¿™å¯èƒ½æ˜¯ä½ è§£å†³é—®é¢˜çš„èµ·ç‚¹ã€‚

</div>

ç¬¬ä¸€ä¸ªå»ºè®®æ˜¯æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦çœŸçš„æ­£ç¡®ï¼Œæ‰€ä»¥é¦–å…ˆè¦åšçš„å°±æ˜¯å¤åˆ¶æ ‡ç­¾å¹¶å°†å…¶ç²˜è´´åˆ° Hub çš„æœç´¢æ ä¸­ï¼š

![The wrong model name.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png "The wrong model name.")

å—¯ï¼Œçœ‹èµ·æ¥ä½ åŒäº‹çš„æ¨¡å‹ç¡®å®ä¸åœ¨ Hub ä¸Šã€‚ä½†æ˜¯ä»”ç»†çœ‹æ¨¡å‹åç§°ä¸­æœ‰ä¸€ä¸ªé”™å­—ï¼DistilBERT çš„åç§°ä¸­åªæœ‰ä¸€ä¸ª "l"ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä¿®æ­£åå¯»æ‰¾ "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"ï¼š

![The right model name.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png "The right model name.")

æ‰¾åˆ°åè®©æˆ‘ä»¬ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹ ID å†æ¬¡ä¸‹è½½æ¨¡å‹ï¼š

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å•Šï¼Œå†æ¬¡æŒ«è´¥ã€‚ä¸è¦æ°”é¦ï¼Œæ¥åˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆçš„æ—¥å¸¸ç”Ÿæ´»ï¼å‰é¢æˆ‘ä»¬å·²ç»ä¿®æ­£äº†æ¨¡å‹ IDï¼Œæ‰€ä»¥é—®é¢˜ä¸€å®šå‡ºåœ¨å­˜å‚¨åº“æœ¬èº«ã€‚è¿™é‡Œæä¾›ä¸€ç§å¿«é€Ÿè®¿é—® Hub ä¸Šå­˜å‚¨åº“å†…å®¹çš„æ–¹æ³•â€”â€”é€šè¿‡ `huggingface_hub` åº“çš„ `list_repo_files()` ï¼š

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

 æœ‰è¶£çš„æ˜¯ä¼¼ä¹æ²¡æœ‰é…ç½®æ–‡ä»¶å­˜å‚¨åº“ä¸­çš„ `config.json` æ–‡ä»¶ï¼éš¾æ€ªæˆ‘ä»¬çš„ `pipeline` æ— æ³•åŠ è½½æ¨¡å‹ï¼›ä½ çš„åŒäº‹ä¸€å®šæ˜¯åœ¨å¾®è°ƒåå¿˜è®°å°†è¿™ä¸ªæ–‡ä»¶ä¸Šä¼ åˆ° Hubã€‚åœ¨è¿™ç§æƒ…å†µä¸‹é—®é¢˜ä¼¼ä¹å¾ˆå®¹æ˜“è§£å†³ï¼šè¦æ±‚ä»–æ·»åŠ æ–‡ä»¶ï¼Œæˆ–è€…ä½ å¯ä»¥ä¸‹è½½æ­¤æ¨¡å‹çš„é…ç½®å¹¶å°†å…¶ä¸Šä¼ åˆ°ä½ ä»¬çš„å­˜å‚¨åº“åæŸ¥çœ‹æ˜¯å¦å¯ä»¥è§£å†³é—®é¢˜ã€‚ä»æ¨¡å‹ ID ä¸­çœ‹åˆ°ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹æ˜¯ [`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased)(https://huggingface.co/distilbert-base-uncased) ï¼Œåœ¨è¿™é‡Œæ¶‰åŠåˆ°ç¬¬äºŒç« ä¸­å­¦ä¹ çš„æŠ€æœ¯ï¼Œä½¿ç”¨ `AutoConfig` ç±»ä¸‹è½½æ¨¡å‹çš„é…ç½®ï¼š

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<div custom-style="Tip-red">

ğŸš¨ åœ¨è¿™é‡Œé‡‡ç”¨çš„æ–¹æ³•å¹¶ä¸æ˜¯ä¸‡æ— ä¸€å¤±çš„ï¼Œå› ä¸ºä½ çš„åŒäº‹å¯èƒ½åœ¨å¾®è°ƒæ¨¡å‹ä¹‹å‰å·²ç»è°ƒæ•´äº† `distilbert-base-uncased` é…ç½®ã€‚æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆåº”è¯¥å¯¹å…¶è¿›è¡Œæ£€æŸ¥ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬å‡è®¾ä½¿ç”¨é»˜è®¤é…ç½®ã€‚

</div>

ä¸Šä¸€æ­¥æˆåŠŸåå¯ä»¥ä½¿ç”¨é…ç½®çš„ `push_to_hub()` æ–¹æ³•å°†å…¶ä¸Šä¼ åˆ°æ¨¡å‹å­˜å‚¨åº“ï¼š

```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

ç°åœ¨å¯ä»¥é€šè¿‡ä»æœ€æ–°æäº¤çš„ `main` åˆ†æ”¯ä¸­åŠ è½½æ¨¡å‹æ¥æµ‹è¯•æ˜¯å¦æœ‰æ•ˆï¼š

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

æˆåŠŸäº†ï¼è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ä½ åˆšåˆšå­¦åˆ°çš„ä¸œè¥¿ï¼š

- Python ä¸­çš„é”™è¯¯æ¶ˆæ¯ç§°ä¸º `tracebacks` ï¼Œæ³¨æ„éœ€è¦ä»ä¸‹åˆ°ä¸Šé˜…è¯»ã€‚é”™è¯¯æ¶ˆæ¯çš„æœ€åä¸€è¡Œé€šå¸¸åŒ…å«å®šä½é—®é¢˜æ ¹æºæ‰€éœ€çš„ä¿¡æ¯ã€‚
- å¦‚æœæœ€åä¸€è¡Œæ²¡æœ‰åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¯·è¿›è¡Œå›æº¯ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥ç¡®å®šæºä»£ç ä¸­å‘ç”Ÿé”™è¯¯çš„ä½ç½®ã€‚
- å¦‚æœæ²¡æœ‰ä»»ä½•é”™è¯¯æ¶ˆæ¯å¯ä»¥å¸®åŠ©ä½ è°ƒè¯•é—®é¢˜ï¼Œè¯·å°è¯•åœ¨çº¿æœç´¢ç±»ä¼¼é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚
- `huggingface_hub` åº“æä¾›äº†ä¸€å¥—å·¥å…·ï¼Œä½ å¯ä»¥ä½¿ç”¨è¿™äº›å·¥å…·ä¸ Hub ä¸Šçš„å­˜å‚¨åº“è¿›è¡Œäº¤äº’å’Œè°ƒè¯•ã€‚

ç°åœ¨ä½ çŸ¥é“å¦‚ä½•è°ƒè¯• `pipeline` ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ¨¡å‹æœ¬èº«å‰å‘ä¼ é€’ä¸­ä¸€ä¸ªæ›´æ£˜æ‰‹çš„ç¤ºä¾‹ã€‚

### è°ƒè¯•æ¨¡å‹çš„å‰å‘ä¼ é€’ 

å°½ç®¡ `pipeline` å¯¹äºå¤§å¤šæ•°éœ€è¦å¿«é€Ÿç”Ÿæˆé¢„æµ‹çš„åº”ç”¨ç¨‹åºæ¥è¯´éå¸¸æœ‰ç”¨ï¼Œä½†æ˜¯æœ‰æ—¶ä½ éœ€è¦è®¿é—®æ¨¡å‹çš„ logits ï¼ˆæ¯”å¦‚ä½ æœ‰ä¸€äº›æƒ³è¦åº”ç”¨çš„è‡ªå®šä¹‰åå¤„ç†ï¼‰ã€‚ä¸ºäº†çœ‹çœ‹åœ¨è¿™ç§æƒ…å†µä¸‹ä¼šå‡ºç°ä»€ä¹ˆé—®é¢˜ï¼Œè®©æˆ‘ä»¬é¦–å…ˆä» `pipeline` ä¸­è·å–æ¨¡å‹å’Œ Tokenizers 

```python
tokenizer = reader.tokenizer
model = reader.model
```

æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦æå‡ºä¸€ä¸ªé—®é¢˜ï¼ŒåŒæ—¶è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªé—®é¢˜æ˜¯å¦æ”¯æŒæˆ‘ä»¬æœ€å–œæ¬¢çš„æ¡†æ¶ï¼š

```python
question = "Which frameworks can I use?"
```

æ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬ä¸ƒç« ä¸­å­¦ä¹ çš„ï¼Œæˆ‘ä»¬éœ€è¦é‡‡å–çš„æ­¥éª¤æ˜¯å¯¹è¾“å…¥è¿›è¡Œæ ‡è®°åŒ–ï¼Œæå–å¼€å§‹å’Œç»“æŸæ ‡è®°çš„å¯¹æ•°ï¼Œç„¶åè§£ç ç­”æ¡ˆèŒƒå›´ï¼š

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
## Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
## Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

çœ‹èµ·æ¥æˆ‘ä»¬çš„ä»£ç ä¸­æœ‰ä¸€ä¸ªé”™è¯¯ï¼ä¸ç”¨ç´§å¼ ï¼Œä½ å¯ä»¥åœ¨ Notebook ä¸­ä½¿ç”¨ Python è°ƒè¯•å™¨ï¼š

æˆ–åœ¨ç»ˆç«¯ä¸­ï¼š

åœ¨è¿™é‡Œï¼Œé”™è¯¯æ¶ˆæ¯å‘Šè¯‰æˆ‘ä»¬ `'list' object has no attribute 'size'` ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ª `-->` ç®­å¤´æŒ‡å‘ `model(**inputs)` ä¸­å‡ºç°é—®é¢˜çš„è¡Œã€‚ä½ å¯ä»¥ä½¿ç”¨ Python è°ƒè¯•å™¨ç”¨äº¤äº’æ–¹å¼æ¥è°ƒè¯•å®ƒï¼Œä½†ç°åœ¨æˆ‘ä»¬åªéœ€æ‰“å°å‡ºä¸€éƒ¨åˆ† `inputs` ï¼Œçœ‹çœ‹æˆ‘ä»¬æœ‰ä»€ä¹ˆï¼š

```python
inputs["input_ids"][:5]
```

```python
[101, 2029, 7705, 2015, 2064]
```

è¿™å½“ç„¶çœ‹èµ·æ¥åƒä¸€ä¸ªæ™®é€šçš„ Python `list` ï¼Œä½†è®©æˆ‘ä»¬ä»”ç»†æ£€æŸ¥ä¸€ä¸‹ç±»å‹ï¼š

```python
type(inputs["input_ids"])
```

```python
list
```

è¿™è‚¯å®šæ˜¯ä¸€ä¸ª Python `list` ã€‚é‚£ä¹ˆå‡ºäº†ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿå›å¿†ç¬¬äºŒç« Transformers ä¸­çš„ `AutoModelForXxx` ç±»åœ¨ `tensors` ä¸Šè¿è¡Œï¼ˆPyTorch æˆ–è€… TensorFlowï¼‰ï¼Œä¸€ä¸ªå¸¸è§çš„æ“ä½œæ˜¯ä½¿ç”¨ `Tensor.size()` æ–¹æ³•æå–å¼ é‡çš„ç»´åº¦ã€‚è®©æˆ‘ä»¬å†å›åˆ°é—®é¢˜å›æº¯ä¸­ï¼Œçœ‹çœ‹å“ªä¸€è¡Œè§¦å‘äº†å¼‚å¸¸ï¼š

```python
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

çœ‹èµ·æ¥æˆ‘ä»¬çš„ä»£ç è¯•å›¾è°ƒç”¨ `input_ids.size()` ï¼Œä½†è¿™æ˜¾ç„¶ä¸é€‚ç”¨äº Python `list` ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå®¹å™¨ã€‚æˆ‘ä»¬å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Ÿåœ¨ Stack Overflow ä¸Šæœç´¢é”™è¯¯æ¶ˆæ¯ç»™å‡ºäº†å¾ˆå¤šç›¸å…³çš„ [hits](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f)(https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f) ã€‚å•å‡»ç¬¬ä¸€ä¸ªä¼šæ˜¾ç¤ºä¸æˆ‘ä»¬ç±»ä¼¼çš„é—®é¢˜ï¼Œç­”æ¡ˆå¦‚ä¸‹é¢çš„å±å¹•æˆªå›¾æ‰€ç¤ºï¼š

![ä» Stack Overflow ä¸Šçš„ä¸€ä¸ªç­”æ¡ˆ.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png "An answer from Stack Overflow.")

è¿™é‡Œå»ºè®®æˆ‘ä»¬æ·»åŠ  `return_tensors='pt'` åˆ° Tokenizerï¼Œè®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æ˜¯å¦é€‚åˆï¼š

```python
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
## ç”¨åˆ†æ•°çš„æœ€å¤§å€¼è·å–æœ€å¯èƒ½çš„ç­”æ¡ˆå¼€å¤´
answer_start = torch.argmax(answer_start_scores)
## ç”¨åˆ†æ•°çš„æœ€å¤§å€¼è·å–æœ€å¯èƒ½çš„ç­”æ¡ˆç»“å°¾
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

 æˆåŠŸäº†ï¼è¿™æ˜¯ Stack Overflow ä¸Šé¢ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ä¾‹å­ï¼Œæœç´¢ç±»ä¼¼çš„é—®é¢˜ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä»ç¤¾åŒºä¸­å…¶ä»–äººçš„ç»éªŒä¸­å—ç›Šã€‚ç„¶è€Œï¼Œåƒè¿™æ ·çš„æœç´¢ä¸æ€»ä¼šäº§ç”Ÿç›¸å…³çš„ç­”æ¡ˆï¼Œå¦‚æ­¤æˆ‘ä»¬æœ‰æ›´å¥½çš„è§£å†³åŠæ³•å—ï¼Ÿç­”æ¡ˆæ˜¯æœ‰çš„ï¼Œæˆ‘ä»¬çš„å¼€å‘è€…ç¤¾åŒº [Hugging Face forums](https://discuss.huggingface.co/)(https://discuss.huggingface.co/) å¯ä»¥å¸®åŠ©ä½ ï¼åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹åœ¨è¯¥å¹³å°ä¸­å¦‚ä½•æœ€å¤§å¯èƒ½å¾—åˆ°é—®é¢˜çš„å›ç­”ã€‚

 ### å¦‚ä½•åœ¨Hugging Faceè®ºå›ä¸Šå¯»æ±‚å¸®åŠ©ï¼Ÿ

 [Hugging Face è®ºå›](https://discuss.huggingface.co)(https://discuss.huggingface.co) æ˜¯ä»å¼€æºå›¢é˜Ÿå’Œæ›´å¹¿æ³›çš„ Hugging Face ç¤¾åŒºè·å¾—å¸®åŠ©çš„å¥½åœ°æ–¹ã€‚ä»¥ä¸‹æ˜¯è®ºå›æŸä¸€å¤©çš„ä¸»é¡µé¢ï¼š

![The Hugging Face forums.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forums.png "The Hugging Face forums.")

åœ¨å·¦ä¾§ï¼Œä½ å¯ä»¥çœ‹åˆ°å„ç§ä¸»é¢˜åˆ†ç»„çš„æ‰€æœ‰ç±»åˆ«ï¼Œè€Œå³ä¾§æ˜¾ç¤ºäº†æœ€æ–°çš„ä¸»é¢˜ã€‚ä¸»é¢˜æ˜¯åŒ…å«æ ‡é¢˜ã€ç±»åˆ«å’Œæè¿°çš„å¸–å­ï¼›å®ƒä¸æˆ‘ä»¬åœ¨åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†æ—¶çœ‹åˆ°çš„ GitHub é—®é¢˜æ ¼å¼éå¸¸ç›¸ä¼¼ [Chapter 5](/course/chapter5)(/course/chapter5) ã€‚é¡¾åæ€ä¹‰ï¼Œ [Beginners](https://discuss.huggingface.co/c/beginners/5)(https://discuss.huggingface.co/c/beginners/5) ç±»åˆ«ä¸»è¦é¢å‘åˆšå¼€å§‹ä½¿ç”¨ Hugging Face åº“å’Œç”Ÿæ€ç³»ç»Ÿçš„äººã€‚æ¬¢è¿ä½ å¯¹ä»»ä½•åº“æå‡ºä»»ä½•é—®é¢˜ï¼Œæ— è®ºæ˜¯è°ƒè¯•ä¸€äº›ä»£ç è¿˜æ˜¯å¯»æ±‚æœ‰å…³å¦‚ä½•åšæŸäº‹çš„å¸®åŠ©ã€‚

åŒæ ·ï¼Œ [Intermediate](https://discuss.huggingface.co/c/intermediate/6)(https://discuss.huggingface.co/c/intermediate/6) å’Œ [Research](https://discuss.huggingface.co/c/research/7)(https://discuss.huggingface.co/c/research/7) ç±»åˆ«ç”¨äºæ›´é«˜çº§çš„é—®é¢˜ï¼Œä¾‹å¦‚ä½ æƒ³è®¨è®ºä¸€äº›æœ€æ–°çš„ NLP ç ”ç©¶ã€‚

å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿåº”è¯¥æåˆ° [Course](https://discuss.huggingface.co/c/course/20)(https://discuss.huggingface.co/c/course/20) ç±»åˆ«ï¼Œä½ å¯ä»¥åœ¨é‡Œé¢æå‡ºä¸ Hugging Face è¯¾ç¨‹ç›¸å…³çš„ä»»ä½•é—®é¢˜ï¼

é€‰æ‹©ç±»åˆ«åï¼Œå°±å¯ä»¥ç¼–å†™ç¬¬ä¸€ä¸ªä¸»é¢˜äº†ã€‚ä½ å¯ä»¥æ‰¾ä¸€äº› [guidelines](https://discuss.huggingface.co/t/how-to-request-support/3128)(https://discuss.huggingface.co/t/how-to-request-support/3128) è¿™äº›è®ºå›ä¼šæ¢è®¨æœ‰å…³å¦‚ä½•æ‰§è¡Œæ­¤æ“ä½œï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€èµ·å­¦ä¹ ä¸€äº›ç”¨æ¥æ„æˆä¸€ä¸ªå¥½ä¸»é¢˜çš„åŠŸèƒ½ã€‚

#### å†™ä¸€ç¯‡é«˜è´¨é‡çš„è®ºå›å¸–å­ 

ä¸¾ä¾‹ï¼Œæˆ‘ä»¬è¦ä» Wikipedia æ–‡ç« ç”ŸæˆåµŒå…¥è¡¨ç¤ºç”¨æ¥åˆ›å»ºè‡ªå®šä¹‰æœç´¢å¼•æ“ã€‚å’Œå‰é¢å¤„ç†ç›¸åŒï¼Œæˆ‘ä»¬æŒ‰å¦‚ä¸‹æ–¹å¼åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹ï¼š

```python
from transformers import AutoTokenizer, AutoModel

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
model = AutoModel.from_pretrained(model_checkpoint)
```

ç°åœ¨æˆ‘ä»¬å°è¯•å°† [Transformers Of Wikipedia](https://en.wikipedia.org/wiki/Transformers)(https://en.wikipedia.org/wiki/Transformers) çš„ä¸€æ•´æ®µè¿›è¡Œçƒ­çŸ¥è¯†ï¼šTransformers ä½œä¸ºä¸€ä¸ª Python åº“è¢«è¶Šæ¥è¶Šå¤šäººç†ŸçŸ¥ï¼‰ï¼š

```python
text = """
Generation One is a retroactive term for the Transformers characters that
appeared between 1984 and 1993. The Transformers began with the 1980s Japanese
toy lines Micro Change and Diaclone. They presented robots able to transform
into everyday vehicles, electronic items or weapons. Hasbro bought the Micro
Change and Diaclone toys, and partnered with Takara. Marvel Comics was hired by
Hasbro to create the backstory; editor-in-chief Jim Shooter wrote an overall
story, and gave the task of creating the characthers to writer Dennis O'Neil.
Unhappy with O'Neil's work (although O'Neil created the name "Optimus Prime"),
Shooter chose Bob Budiansky to create the characters.

The Transformers mecha were largely designed by ShÅji Kawamori, the creator of
the Japanese mecha anime franchise Macross (which was adapted into the Robotech
franchise in North America). Kawamori came up with the idea of transforming
mechs while working on the Diaclone and Macross franchises in the early 1980s
(such as the VF-1 Valkyrie in Macross and Robotech), with his Diaclone mechs
later providing the basis for Transformers.

The primary concept of Generation One is that the heroic Optimus Prime, the
villainous Megatron, and their finest soldiers crash land on pre-historic Earth
in the Ark and the Nemesis before awakening in 1985, Cybertron hurtling through
the Neutral zone as an effect of the war. The Marvel comic was originally part
of the main Marvel Universe, with appearances from Spider-Man and Nick Fury,
plus some cameos, as well as a visit to the Savage Land.

The Transformers TV series began around the same time. Produced by Sunbow
Productions and Marvel Productions, later Hasbro Productions, from the start it
contradicted Budiansky's backstories. The TV series shows the Autobots looking
for new energy sources, and crash landing as the Decepticons attack. Marvel
interpreted the Autobots as destroying a rogue asteroid approaching Cybertron.
Shockwave is loyal to Megatron in the TV series, keeping Cybertron in a
stalemate during his absence, but in the comic book he attempts to take command
of the Decepticons. The TV series would also differ wildly from the origins
Budiansky had created for the Dinobots, the Decepticon turned Autobot Jetfire
(known as Skyfire on TV), the Constructicons (who combine to form
Devastator),[19][20] and Omega Supreme. The Marvel comic establishes early on
that Prime wields the Creation Matrix, which gives life to machines. In the
second season, the two-part episode The Key to Vector Sigma introduced the
ancient Vector Sigma computer, which served the same original purpose as the
Creation Matrix (giving life to Transformers), and its guardian Alpha Trion.
"""

inputs = tokenizer(text, return_tensors="pt")
logits = model(**inputs).logits
```

```python
IndexError: index out of range in self
```

æˆ‘ä»¬é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜â€”â€”é”™è¯¯ä¿¡æ¯æœ‰äº›å¥‡æ€ª [section 2](/course/chapter8/section2)(/course/chapter8/section2) ï¼æˆ‘ä»¬æ— æ³•ç¡®å®šå®Œæ•´å›æº¯çš„æ­£åå‘ï¼Œè¿™æ—¶æˆ‘ä»¬å¯ä»¥è½¬å‘ Hugging Face è®ºå›å¯»æ±‚å¸®åŠ©ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•æ’°å†™é—®é¢˜çš„ä¸»é¢˜ï¼Ÿ

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç‚¹å‡»å³ä¸Šè§’çš„â€œæ–°å»ºä¸»é¢˜â€æŒ‰é’®ï¼ˆæ³¨æ„ï¼Œè¦åˆ›å»ºä¸»é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ç™»å½•ï¼‰ï¼š

![Creating a new forum topic.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forums-new-topic.png "Creating a new forum topic.")

è¿™é‡Œä¼šå‡ºç°ä¸€ä¸ªå†™ä½œç•Œé¢ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…¶ä¸­è¾“å…¥æˆ‘ä»¬çš„ä¸»é¢˜æ ‡é¢˜ï¼Œé€‰æ‹©ä¸€ä¸ªç±»åˆ«ï¼Œå¹¶èµ·è‰å†…å®¹ï¼š

![The interface for creating a forum topic.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forum-topic01.png "The interface for creating a forum topic.")

ç”±äºé”™è¯¯ä¼¼ä¹ä»…ä¸ Transformers æœ‰å…³ï¼Œå› æ­¤æˆ‘ä»¬å°†ä¸ºé”™è¯¯é€‰æ‹©è¯¥ç±»åˆ«ã€‚ç¬¬ä¸€æ¬¡å°è¯•è§£é‡Šè¿™ä¸ªé—®é¢˜å¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

![Drafting the content for a new forum topic.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forum-topic02.png "Drafting the content for a new forum topic.")

å°½è¿™ä¸ªä¸»é¢˜åŒ…å«è¿™ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œä½†æ’°å†™æ–¹å¼å­˜åœ¨ä¸€äº›é—®é¢˜ï¼š

1. æ ‡é¢˜æè¿°æ€§ä¸æ˜¯å¾ˆå¼ºï¼Œè¿™ä¼šå¯¼è‡´æµè§ˆè®ºå›çš„äººåœ¨ä¸é˜…è¯»æ­£æ–‡çš„æƒ…å†µä¸‹æ— æ³•åˆ†è¾¨å‡ºä¸»é¢˜çš„å†…å®¹ã€‚

2. æ­£æ–‡æ²¡æœ‰æä¾›è¶³å¤Ÿçš„ä¿¡æ¯è¯´æ˜é”™è¯¯çš„æ¥æºä»¥åŠå¦‚ä½•é‡ç°é”™è¯¯ã€‚

3. è¿™ä¸ªè¯é¢˜ä¸‹çš„è¯­æ°”æœ‰äº›è‹›åˆ»ã€‚

åƒè¿™æ ·çš„ä¸»é¢˜ä¸å¤ªå¯èƒ½å¾ˆå¿«å¾—åˆ°ç­”æ¡ˆï¼Œéœ€è¦å¯¹å…¶è¿›è¡Œæ”¹è¿›ã€‚æˆ‘ä»¬å°†ä»é€‰æ‹©ä¸€ä¸ªé—®é¢˜çš„å¥½æ ‡é¢˜å¼€å§‹ã€‚

##### é€‰æ‹©æè¿°æ€§æ ‡é¢˜ 

å¦‚æœä½ æƒ³å°±ä»£ç ä¸­çš„é”™è¯¯å¯»æ±‚å¸®åŠ©ï¼Œç»éªŒæ³•åˆ™æ˜¯åœ¨æ ‡é¢˜ä¸­åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä»¥ä¾¿å…¶ä»–äººå¯ä»¥å¿«é€Ÿç¡®å®šä»–ä»¬æ˜¯å¦å¯ä»¥å›ç­”ä½ çš„é—®é¢˜ã€‚åœ¨æˆ‘ä»¬çš„è¿è¡Œç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“æ­£åœ¨å¼•å‘çš„å¼‚å¸¸åç§°ï¼Œå¹¶æœ‰ä¸€äº›æç¤ºè¡¨ç¤ºå®ƒæ˜¯åœ¨æ¨¡å‹çš„å‰å‘ä¼ é€’ä¸­è§¦å‘çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è°ƒç”¨ `model(**inputs)` ã€‚ä¸ºäº†ä¼ è¾¾è¿™ä¸€ç‚¹ï¼Œä¸€ä¸ªå¯èƒ½çš„æ ‡é¢˜å¯èƒ½æ˜¯ï¼š

> è‡ªåŠ¨å»ºæ¨¡æ­£å‘ä¼ é€’ä¸­çš„ç´¢å¼•é”™è¯¯çš„æ¥æºï¼Ÿ

è¿™ä¸ªæ ‡é¢˜å‘Šè¯‰è¯»è€…åœ¨å“ªé‡Œä½ è®¤ä¸ºé”™è¯¯æ¥è‡ªï¼Œå¦‚æœä»–ä»¬é‡åˆ°äº† `IndexError` åœ¨æ­¤ä¹‹å‰ï¼Œä»–ä»¬å¾ˆæœ‰å¯èƒ½çŸ¥é“å¦‚ä½•è°ƒè¯•å®ƒã€‚å½“ç„¶ï¼Œæ ‡é¢˜ä¹Ÿå¯ä»¥æ˜¯å…¶ä»–å˜ä½“ï¼Œä¾‹å¦‚ï¼š

> ä¸ºä»€ä¹ˆæˆ‘çš„æ¨¡å‹ä¼šäº§ç”Ÿç´¢å¼•é”™è¯¯ï¼Ÿ

è¿™ç§æ ‡é¢˜ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæè¿°æ€§çš„æ ‡é¢˜ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æ”¹å–„ä¸»ä½“ã€‚

##### è®¾ç½®ä»£ç æ®µçš„æ ¼å¼ 

ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæè¿°æ€§çš„æ ‡é¢˜ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•æ”¹å–„ä»£ç æ®µçš„æ ¼å¼ã€‚åœ¨ IDE ä¸­é˜…è¯»æºä»£ç å·²ç»å¤Ÿéš¾çš„äº†ï¼Œä½†æ˜¯å½“å°†ä»£ç å¤åˆ¶ç²˜è´´ä¸ºçº¯æ–‡æœ¬æ—¶å°±æ›´éš¾äº†ï¼ä¸è¿‡ Hugging Face è®ºå›æ”¯æŒä½¿ç”¨ Markdownï¼Œæ ‡å‡†æ ¼å¼æ˜¯ç”¨ä¸‰ä¸ªåå¼•å· ï¼ˆ```ï¼‰ å°†ä»£ç å—æ‹¬èµ·æ¥ã€‚è¿™å¯ä»¥è®©æ­£æ–‡æ¯”æˆ‘ä»¬çš„åŸå§‹ç‰ˆæœ¬çœ‹èµ·æ¥æ›´åŠ ç¾è§‚ï¼š

![Our revised forum topic, with proper code formatting.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forum-topic03.png "Our revised forum topic, with proper code formatting.")

æ­£å¦‚ä½ åœ¨å±å¹•æˆªå›¾ä¸­çœ‹åˆ°çš„ï¼Œå°†ä»£ç å—æ‹¬åœ¨åå¼•å·ä¸­ä¼šå°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºæ ¼å¼åŒ–ä»£ç ï¼Œå¹¶å¸¦æœ‰é¢œè‰²æ ·å¼ï¼å¦å¤–ï¼Œå•ä¸ªåå¼•å·å¯ç”¨äºæ ¼å¼åŒ–å†…è”å˜é‡ï¼Œæ¯”å¦‚ `distilbert-base-uncased` è¿™æ ·ã€‚æ­¤æ—¶è¿™ä¸ªé—®é¢˜çœ‹èµ·æ¥å¥½å¤šäº†ï¼Œæˆ‘ä»¬è¿˜æœ‰å¯èƒ½åœ¨ç¤¾åŒºä¸­æ‰¾åˆ°å›ç­”é”™è¯¯åŸå› çš„æ˜¯ä»€ä¹ˆçš„äººã€‚ç„¶è€Œï¼Œä¸å…¶ä¾é è¿æ°”ï¼Œä¸å¦‚æŠŠå®Œæ•´çš„å›æº¯ç»†èŠ‚åŒ…æ‹¬è¿›æ¥ï¼Œå¯ä»¥æ›´å¥½åœ°æ‰¾åˆ°é—®é¢˜ç­”æ¡ˆã€‚

##### åŒ…æ‹¬å®Œæ•´çš„å›æº¯ 

ç”±äºå›æº¯çš„æœ€åä¸€è¡Œé€šå¸¸å·²ç»åŒ…å«è¶³å¤Ÿçš„ä»£ç é—®é¢˜ä¿¡æ¯ï¼Œå› æ­¤å¾ˆå¯èƒ½åœ¨é—®é¢˜å¸–å­ä¸­æä¾›è¿™ä¸ªæ¥â€œèŠ‚çœç©ºé—´â€ã€‚ç„¶è€Œï¼Œå®é™…ä¸Šå¯¹äºä½ ä»¥å¤–çš„å…¶ä»–äººæ¥è¯´å¾ˆéš¾å»ç€æ‰‹è°ƒè¯•é—®é¢˜ï¼Œæ‰€ä»¥æä¾›åœ¨å›æº¯ä¸­è¾ƒä¸Šé¢çš„ä¿¡æ¯ä¹Ÿæ˜¯å¿…è¦çš„ã€‚æœ€å¥½çš„åšæ³•æ˜¯å¤åˆ¶å¹¶ç²˜è´´æ‰€æœ‰çš„å›æº¯ï¼ŒåŒæ—¶ç¡®ä¿å®ƒçš„æ ¼å¼ä¸è¢«ç ´åã€‚ä½†æ˜¯è¿™äº›å›æº¯å¯èƒ½ä¼šå¾ˆé•¿ï¼Œæ‰€ä»¥å¯ä»¥åœ¨å¯¹æºä»£ç è¿›è¡Œè§£é‡Šä¹‹åå†å±•ç¤ºå®ƒä»¬ã€‚å°±è¿™ä¸ªæ€è·¯ç°åœ¨æ¥å¯¹æˆ‘ä»¬çš„é—®é¢˜å¸–å­è¿›è¡Œä¿®æ”¹ï¼Œæˆ‘ä»¬çš„å¸–å­å¦‚ä¸‹æ‰€ç¤ºï¼š

![Our example forum topic, with the complete traceback.](https:/huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forum-topic04.png "Our example forum topic, with the complete traceback.")

è¿™æä¾›äº†æ›´å¤šä¿¡æ¯ï¼Œç»†å¿ƒçš„è¯»è€…å¯èƒ½ä¼šæŒ‡å‡ºé—®é¢˜ä¼¼ä¹æ˜¯ç”±äºå›æº¯ä¸­çš„è¿™ä¸€è¡Œè€Œä¼ é€’äº†ä¸€ä¸ªé•¿è¾“å…¥ï¼š

> ä»¤ç‰Œç´¢å¼•åºåˆ—é•¿åº¦é•¿äºä¸ºæ­¤æ¨¡å‹æŒ‡å®šçš„æœ€å¤§åºåˆ—é•¿åº¦ ï¼ˆ583 > 512ï¼‰ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œç¡®å®šé—®é¢˜æ‰€åœ¨è¿˜éœ€è¦æä¾›é€šè¿‡æä¾›è§¦å‘é”™è¯¯çš„å¯¹åº”ä»£ç ã€‚

##### æä¾›å¯é‡å¤çš„ç¤ºä¾‹ 

å¦‚æœä½ æ›¾ç»å°è¯•è¿‡è°ƒè¯•å…¶ä»–äººçš„ä»£ç ï¼Œé‚£ä¹ˆä½ å¯èƒ½é¦–å…ˆå°è¯•é‡ç°ä»–ä»¬æŠ¥å‘Šçš„é—®é¢˜ï¼Œä»¥ä¾¿å¯ä»¥é€šè¿‡å›æº¯æ¥æŸ¥æ˜é”™è¯¯ã€‚åœ¨è®ºå›ä¸Šè·å¾—ï¼ˆæˆ–æä¾›ï¼‰å¸®åŠ©æ—¶æ²¡æœ‰ä»€ä¹ˆä¸åŒï¼Œå¦‚æœä½ èƒ½æä¾›ä¸€ä¸ªé‡ç°é”™è¯¯çš„å°ä¾‹å­çœŸçš„å¾ˆæœ‰å¸®åŠ©ã€‚è¿™é‡Œæœ‰ä¸ªç¤ºä¾‹å¸–å­ï¼š

![The final version of our forum topic.](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/forum-topic05.png "The final version of our forum topic.")

è¯¥å¸–å­ç›®å‰åŒ…å«ç›¸å½“å¤šçš„ä¿¡æ¯ï¼Œå¹¶ä¸”å®ƒçš„æ’°å†™æ ¼å¼æ›´å¯èƒ½å¸å¼•ç¤¾åŒºçš„æ³¨æ„ï¼Œè·å¾—æœ‰ç”¨çš„ç­”æ¡ˆã€‚æœ‰äº†è¿™äº›åŸºæœ¬æŒ‡å—ï¼Œä½ ç°åœ¨å¯ä»¥åˆ›å»ºå¾ˆæ£’çš„å¸–å­æ¥æ‰¾åˆ°é‡åˆ°çš„ Transformers é—®é¢˜çš„ç­”æ¡ˆï¼

### å¦‚ä½•æå‡ºä¸€ä¸ªå¥½é—®é¢˜ 

å½“ä½ é‡åˆ° Hugging Face åº“ä¸­çš„ä¸€ä¸ªçœ‹èµ·æ¥ä¸æ­£ç¡®çš„ä¸œè¥¿æ—¶ï¼Œè¯·åŠæ—¶å‘ŠçŸ¥æˆ‘ä»¬ä»¥ä¾¿å¯ä»¥ä¿®å¤å®ƒã€‚å¦‚æœä½ ä¸èƒ½å®Œå…¨ç¡®å®šé”™è¯¯æ˜¯åœ¨ä½ è‡ªå·±çš„ä»£ç è¿˜æ˜¯åœ¨æˆ‘ä»¬çš„æŸä¸ªåº“ä¸­ï¼Œé¦–å…ˆå¯ä»¥åœ¨ [forums](https://discuss.huggingface.co)(https://discuss.huggingface.co) ç¤¾åŒºè¿›è¡Œæœç´¢ã€‚ç¤¾åŒºä¼šå¸®åŠ©ä½ è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒHugging Face å›¢é˜Ÿä¹Ÿä¼šå¯†åˆ‡å…³æ³¨è¿™é‡Œçš„è®¨è®ºã€‚

å½“ä½ ç¡®å®šæ˜¯åº“æœ‰é”™è¯¯æ—¶ï¼Œç¬¬ä¸€æ­¥å¯ä»¥æ„å»ºä¸€ä¸ªæœ€å°çš„å¯é‡ç°ç¤ºä¾‹ã€‚

#### åˆ›å»ºä¸€ä¸ªæœ€å°çš„å¯é‡ç°ç¤ºä¾‹ 

éš”ç¦»äº§ç”Ÿé”™è¯¯çš„ä»£ç æ®µéå¸¸é‡è¦ã€‚é¡¾åæ€ä¹‰ï¼Œæœ€å°çš„å¯é‡ç°ç¤ºä¾‹åº”è¯¥æ˜¯å¯é‡ç°çš„ï¼Œå®ƒä¸åº”ä¾èµ–äºä½ å¯èƒ½æ‹¥æœ‰çš„ä»»ä½•å¤–éƒ¨æ–‡ä»¶æˆ–æ•°æ®ã€‚è¿™ä»£è¡¨éœ€è¦ç”¨ä¸€äº›çœ‹èµ·æ¥åƒçœŸå®å€¼çš„è™šæ‹Ÿå€¼æ›¿æ¢æ­£åœ¨ä½¿ç”¨çš„æ•°æ®ï¼Œä½†è¿™ä»ç„¶ä¼šäº§ç”Ÿç›¸åŒçš„é”™è¯¯ã€‚

<div custom-style="Tip-red">

ğŸš¨Transformers å­˜å‚¨åº“ä¸­çš„è®¸å¤šé—®é¢˜éƒ½æ²¡æœ‰è§£å†³ï¼Œå› ä¸ºç”¨äºå¤åˆ¶å®ƒä»¬çš„æ•°æ®ä¸å¯è®¿é—®ã€‚

</div>

å¦‚æœä½ æœ‰ä¸€äº›è‡ªå®šä¹‰çš„ä¸œè¥¿ï¼Œå°½é‡å‡å°‘å®ƒæ‰€åœ¨çš„ä»£ç è¡Œï¼Œæ„å»ºæˆ‘ä»¬æ‰€è°“çš„æœ€å°çš„å¯é‡å¤ç¤ºä¾‹ã€‚è™½ç„¶è¿™å¯èƒ½éœ€è¦ä½ åšæ›´å¤šçš„å·¥ä½œï¼Œä½†å¦‚æœå¯ä»¥æä¾›ä¸€ä¸ªæ¼‚äº®çš„ã€ç®€çŸ­çš„é”™è¯¯é‡ç°å™¨ï¼Œå‡ ä¹å¯ä»¥ä¿è¯å¾—åˆ°å¸®åŠ©å’Œä¿®å¤ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œä½ ä¹Ÿå¯ä»¥æ£€æŸ¥å‘ç”Ÿé”™è¯¯çš„æºä»£ç ä»è€Œå¯èƒ½æ‰¾åˆ°é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶è¿™ä¹Ÿå¯ä»¥å¸®åŠ©ç»´æŠ¤äººå‘˜åœ¨é˜…è¯»ä½ çš„æŠ¥å‘Šæ—¶æ›´å¥½åœ°ç†è§£æ¥æºã€‚

#### å¡«å†™é—®é¢˜æ¨¡æ¿ 

å½“ä½ æäº¤é—®é¢˜æ—¶ï¼Œéœ€è¦å¡«å†™ä¸€ä¸ªæ¨¡æ¿ã€‚å¯ä»¥æŒ‰ç…§è¿™ä¸ªé“¾æ¥ [Transformers issues](https://github.com/huggingface/transformers/issues/new/choose)(https://github.com/huggingface/transformers/issues/new/choose) è¿›è¡Œæ“ä½œï¼Œä½†æ˜¯å¦‚æœä½ åœ¨å¦ä¸€ä¸ªå­˜å‚¨åº“ä¸­æŠ¥å‘Šé—®é¢˜ï¼Œéœ€è¦ç›¸åŒç±»å‹çš„ä¿¡æ¯ã€‚è¯·ä¸è¦å°†æ¨¡æ¿ç•™ç©ºï¼Œæ¨¡æ¿å¯ä»¥æœ€å¤§é™åº¦æé«˜è·å¾—ç­”æ¡ˆå’Œè§£å†³é—®é¢˜çš„æœºä¼šã€‚

##### æä¾›ç¯å¢ƒä¿¡æ¯ 

Transformers æä¾›äº†ä¸€ä¸ªå®ç”¨ç¨‹åºæ¥è·å–æœ‰å…³äºä½ ç¯å¢ƒçš„æ‰€æœ‰ä¿¡æ¯ã€‚åªéœ€åœ¨ç»ˆç«¯ä¸­è¾“å…¥ä»¥ä¸‹å†…å®¹ï¼š

```python
transformers-cli env
```

å°†å¾—åˆ°ä»¥ä¸‹è¾“å‡ºï¼š

```python
Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.

- `transformers` version: 4.12.0.dev0
- Platform: Linux-5.10.61-1-MANJARO-x86_64-with-arch-Manjaro-Linux
- Python version: 3.7.9
- PyTorch version (GPU?): 1.8.1+cu111 (True)
- Tensorflow version (GPU?): 2.5.0 (True)
- Flax version (CPU?/GPU?/TPU?): 0.3.4 (cpu)
- Jax version: 0.2.13
- JaxLib version: 0.1.65
- Using GPU in script?: <fill in>
- Using distributed or parallel set-up in script?: <fill in>
```

ä½ è¿˜å¯ä»¥åœ¨ `transformers-cli env` å‘½ä»¤å¼€å§‹å‰æ·»åŠ ä¸€ä¸ª `!` ï¼Œä» notebook å•å…ƒæ‰§è¡Œå®ƒï¼Œç„¶åæŠŠç»“æœå¤åˆ¶åœ¨ä½ é—®é¢˜å¸–å­çš„å¼€å¤´ã€‚

##### æ ‡è®°äººå‘˜ 

é€šè¿‡é”®å…¥ `@` åè·Ÿä¸Š GitHub å¥æŸ„æ¥æ ‡è®°ä»–äººï¼Œå¯ä»¥å‘ä»–ä»¬å‘é€é€šçŸ¥ï¼Œè¿™æ ·ä»–ä»¬å°±ä¼šçœ‹åˆ°ä½ çš„é—®é¢˜æ¥å°½å¯èƒ½æ›´å¿«åœ°å›å¤ä½ ã€‚å¦‚æœä½ æ ‡è®°çš„äººä¸æ‚¨çš„é—®é¢˜æ²¡æœ‰ç›´æ¥è”ç³»è¯·è°¨æ…ä½¿ç”¨ï¼Œå› ä¸ºä»–ä»¬å¯èƒ½ä¸å–œæ¬¢æ”¶åˆ°é€šçŸ¥ã€‚å¦‚æœä½ æŸ¥çœ‹äº†ä¸æ‚¨çš„é”™è¯¯ç›¸å…³çš„æºæ–‡ä»¶ï¼Œå°±åº”è¯¥æ ‡è®°ä¸Šä¸€æ¬¡å¯¹ä½ è®¤ä¸ºé€ æˆé—®é¢˜çš„è¡Œè¿›è¡Œä¿®æ”¹çš„äººï¼ˆå¯ä»¥åœ¨ GitHub ä¸ŠæŸ¥çœ‹è¯¥è¡Œï¼Œé€‰æ‹©å®ƒç„¶åç‚¹å‡» "View git blame"ï¼‰ã€‚
å¦‚æœæ²¡æœ‰è¿›è¡Œæ ‡è®°ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„æ¨¡æ¿ä¼šè‡ªåŠ¨æä¾›è¦æ ‡è®°çš„äººçš„å»ºè®®ã€‚ä¸€èˆ¬ä¸è¦æ ‡è®°è¶…è¿‡ä¸‰ä¸ªäººã€‚

##### åŒ…å«ä¸€ä¸ªå¯é‡å¤çš„ç¤ºä¾‹ 

å¦‚æœä½ å·²ç»åˆ›å»ºäº†ä¸€ä¸ªäº§ç”Ÿé”™è¯¯çš„ç‹¬ç«‹ç¤ºä¾‹ï¼Œè¯·é”®å…¥ä¸€è¡ŒåŒ…å«ä¸‰ä¸ªåå¼•å·ï¼Œåè·Ÿ `python` ï¼Œåƒè¿™æ ·ï¼š

```python
```python  
```

ç„¶åç²˜è´´æœ€å°å¯é‡ç°ç¤ºä¾‹å¹¶é”®å…¥ä¸€ä¸ªå¸¦æœ‰ä¸‰ä¸ªåå¼•å·çš„æ–°è¡Œã€‚è¿™å°†ç¡®ä¿ä½ çš„ä»£ç æ ¼å¼æ­£ç¡®ã€‚å¦‚æœä½ æ²¡æœ‰è®¾æ³•åˆ›å»ºå¯é‡ç°çš„ç¤ºä¾‹ï¼Œè¯·ä»¥æ¸…æ™°çš„æ­¥éª¤è§£é‡Šä½ æ˜¯å¦‚ä½•è§£å†³é—®é¢˜çš„ã€‚å¦‚æœå¯ä»¥ï¼Œè¯·åŒ…å«æŒ‡å‘é”™è¯¯æ‰€åœ¨çš„ Google Colab ç¬”è®°æœ¬çš„é“¾æ¥ã€‚ä½ åˆ†äº«çš„ä¿¡æ¯è¶Šå¤šï¼Œç»´æŠ¤è€…å°±è¶Šæœ‰èƒ½åŠ›å›å¤ä½ ã€‚åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œä½ éƒ½åº”è¯¥å¤åˆ¶å¹¶ç²˜è´´ä½ æ”¶åˆ°çš„æ•´ä¸ªé”™è¯¯æ¶ˆæ¯ã€‚å¦‚æœä½ åœ¨ Colab ä¸­å·¥ä½œï¼Œè¯·è®°ä½ï¼Œå †æ ˆè·Ÿè¸ªä¸­çš„æŸäº›å¸§å¯èƒ½ä¼šè‡ªåŠ¨æŠ˜å ï¼Œå› æ­¤è¯·ç¡®ä¿åœ¨å¤åˆ¶ä¹‹å‰å±•å¼€å®ƒä»¬ã€‚ä¸ä»£ç ç¤ºä¾‹ä¸€æ ·ï¼Œå°†è¯¥é”™è¯¯æ¶ˆæ¯æ”¾åœ¨ä¸¤è¡Œä¹‹é—´ï¼Œå¹¶å¸¦æœ‰ä¸‰ä¸ªåå¼•å·ï¼Œå› æ­¤æ ¼å¼æ­£ç¡®ã€‚

##### æè¿°é¢„æœŸè¡Œä¸º 

ç”¨å‡ è¡Œæ¥è§£é‡Šä½ æœŸæœ›å¾—åˆ°ä»€ä¹ˆï¼Œæ¥å¸®åŠ©ç»´æŠ¤äººå‘˜å®Œå…¨æŒæ¡é—®é¢˜ã€‚è¿™éƒ¨åˆ†é€šå¸¸å¾ˆæ˜æ˜¾ï¼Œæ‰€ä»¥åº”è¯¥ç”¨ä¸€å¥è¯æ¥å½¢å®¹ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½æœ‰å¾ˆå¤šè¯è¦è¯´ã€‚

#### æäº¤

æäº¤ä½ çš„é—®é¢˜åï¼Œè¯·ç¡®ä¿å¿«é€Ÿæ£€æŸ¥ä¸€åˆ‡æ˜¯å¦æ­£å¸¸ã€‚å¦‚æœä½ çŠ¯äº†é”™è¯¯ï¼Œä½ å¯ä»¥ç¼–è¾‘é—®é¢˜ï¼Œæˆ–è€…å¦‚æœä½ å‘ç°é—®é¢˜ä¸ä½ æœ€åˆçš„æƒ³æ³•ä¸åŒï¼Œç”šè‡³å¯ä»¥æ›´æ”¹å…¶æ ‡é¢˜ã€‚å¦‚æœä½ æ²¡æœ‰å¾—åˆ°ç­”æ¡ˆï¼Œå°±æ²¡æœ‰å¿…è¦å¯¹äººè¿›è¡Œ ping æ“ä½œã€‚å¦‚æœå‡ å¤©å†…æ²¡æœ‰äººå¸®åŠ©ä½ ï¼Œå¾ˆå¯èƒ½æ²¡æœ‰äººèƒ½ç†è§£ä½ çš„é—®é¢˜ã€‚ä¸è¦çŠ¹è±«ï¼Œå›åˆ°å¯é‡ç°çš„ä¾‹å­ã€‚å¯ä»¥å°½é‡å°è¯•è®©å®ƒæ›´çŸ­æ›´åˆ‡é¢˜ï¼Ÿå¦‚æœåœ¨ä¸€å‘¨å†…æ²¡æœ‰å¾—åˆ°ç­”å¤ï¼Œå¯ä»¥ç•™è¨€å¯»æ±‚å¸®åŠ©ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ å·²ç»æŠŠé—®é¢˜ç¼–è¾‘çš„åŒ…å«æœ‰å…³è¯¥é—®é¢˜çš„æ›´å¤šä¿¡æ¯äº†ã€‚