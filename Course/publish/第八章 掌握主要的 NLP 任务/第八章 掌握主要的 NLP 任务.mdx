

# 第八章 掌握主要的 NLP 任务 

在第四章，你了解了如何微调文本分类模型。在本章中，我们将处理以下常见的 NLP 任务：

- Token 分类
- 掩码语言建模（如 BERT）
- 文本摘要
- 翻译
- 因果语言建模预训练（如 GPT-2）
- 问答

{#if fw === 'pt'}

为此，你需要充分利用在第四章中学到的有关 `Trainer` API 和 Accelerate 库的知识，以及在第六章中学到的 Datasets 库和第七章中学到的 Tokenizers 库的知识。我们还会像在第五章中那样将结果上传到 Model Hub，所以这真的是所有所学内容融会贯通的一章！

本章的每个部分都可以独立阅读，它们将向你展示如何使用 `Trainer` API 或自己的训练循环来训练模型，同时使用 Accelerate 加速。你可以随意跳过其中任意部分，重点关注你最感兴趣的部分： `Trainer` API 非常适合微调（fine-tuning）或训练模型，而无需担心背后的细节，而使用 `Accelerate` 的训练循环将使你更容易自定义所需的任何结构。

{:else}

为此，你需要充分利用在第四章中学到的有关 `Keras` API、第六章中的 Datasets 库以及第七章中的 Tokenizers 库的所有知识。我们还会像在第五章中那样将结果上传到 Model Hub，所以这真的是所有所学内容融会贯通的一章！

本章每个部分都可以独立阅读。

{/if}

<div custom-style="Tip-green">

如果你按顺序阅读这些部分，你会注意到它们在代码和描述上有许多相似之处。这种重复是有意为之的，让你可以随时钻研（或稍后再回看）任何你感兴趣的任务并找到一个完整的可运行示例。

</div>
